# -*- coding: utf-8 -*-
"""Exp1 Deep Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ll9hi3yl7L9ANA95VpAZf45HyyGwJFj7

**Predicting Diabetes Disease Progression Based on Patient Health Metrics**

**Problem Description:**
The goal is to predict the progression of diabetes one year after baseline measurements using a set of clinical features collected from patients. The dataset contains various health metrics like Pregnancies, Glucose, SkinThickness, age, BMI, blood pressure, Insulin, DiabetesPedigreeFunction.

**Dataset Link:**https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset?resource=download

**Import Libraries**
"""

# Step 1: Import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

"""**Load Dataset**"""

# Step 2: Load Dataset

data = pd.read_csv('D:\Deep Learning\Dataset\diabetes.csv')

"""**NumPy Practice**"""

# Step 3: NumPy Practice

# Array creation
a = np.array([1, 2, 3])
b = np.arange(0, 10, 2)
c = np.zeros((2, 3))
d = np.ones((3, 2))

print("Array a:", a)
print("Array b:", b)
print("Array c:\n", c)
print("Array d:\n", d)

# Reshaping and flattening
reshaped = d.reshape((2, 3))
flattened = d.flatten()
print("Reshaped d:\n", reshaped)
print("Flattened d:", flattened)

# Math operations
print("Mean of b:", b.mean())
print("Sum of b:", b.sum())
print("Max of b:", b.max())
print("Min of b:", b.min())

# Random number generation
rand_arr = np.random.rand(5)      # Uniform [0, 1)
randn_arr = np.random.randn(5)    # Standard normal

print("Random uniform array:", rand_arr)
print("Random normal array:", randn_arr)

"""**Pandas: Data Exploration and Cleaning data**"""

# Step 4: Pandas: Data Exploration and Cleaning data
# Basic DataFrame operations
print(data.head())
print("\nDataFrame info:")
print(data.info())
print("\nDataFrame statistics:")
print(data.describe())

# Select columns, filter rows, sort
print("\nFirst 5 Ages:", data['Age'].head())
print("\nFilter Outcome=1 (Diabetic):")
print(data[data['Outcome']==1].head())

print("\nSort by Glucose descending:")
print(data.sort_values('Glucose', ascending=False).head())

# Handle missing values
print("Missing values per column:\n", data.isnull().sum())
# If zeros mean missing (often true for Glucose, BP, etc.), replace with NaN:
cols_with_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
data[cols_with_missing] = data[cols_with_missing].replace(0, np.nan)
print("Post zero-to-NaN missing:\n", data.isnull().sum())
# Fill missing with median as example:
data_filled = data.fillna(data.median(numeric_only=True))

# Grouping, value counts
print(data['Outcome'].value_counts())
print(data.groupby('Outcome')['Age'].mean())

"""**Matplotlib: Visualization Examples**"""

# Step 5. Matplotlib: Visualization Examples

# Line plot
plt.plot(data['Age'].head(20), label='Age List')
plt.title("Ages (First 20)")
plt.xlabel("Index")
plt.ylabel("Age")
plt.legend()
plt.show()

# # Bar plot
# age_counts = data['Age'].value_counts().sort_index()
# plt.bar(age_counts.index, age_counts.values)
# plt.title("Age Distribution")
# plt.xlabel("Age")
# plt.ylabel("Count")
# plt.show()

# Histogram
plt.hist(data_filled['BMI'], bins=20)
plt.title("BMI Distribution")
plt.xlabel("BMI")
plt.ylabel("Frequency")
plt.show()

# Display image-style array (for illustration)
plt.imshow(np.random.rand(10,10), cmap='viridis')
plt.title("Random Image")
plt.colorbar()
plt.show()

"""**Seaborn: Advanced Visualization**"""

# Step 6: Seaborn: Advanced Visualization
# Distribution plot
sns.histplot(data_filled['Glucose'], kde=True)
plt.title('Glucose Distribution')
plt.show()

# Boxplot
sns.boxplot(x='Outcome', y='BMI', data=data_filled)
plt.title('BMI by Diabetes Status')
plt.show()

# Countplot
sns.countplot(x='Outcome', data=data)
plt.title('Diabetes Outcome Counts')
plt.show()

# Heatmap: Correlation matrix
plt.figure(figsize=(8,6))
sns.heatmap(data_filled.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

# Pairplot
sns.pairplot(data_filled, hue='Outcome', plot_kws={'alpha':0.5})
plt.show()

"""**TensorFlow/Keras: Simple Classifier**"""

# Step 7: TensorFlow/Keras: Simple Classifier

# Prepare data
X = data_filled.drop('Outcome', axis=1).values
y = data_filled['Outcome'].values

# Split into train/test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define model
model = Sequential([
    Dense(16, activation='relu', input_shape=(X.shape[1],)),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=16)

# Evaluate
loss, acc = model.evaluate(X_test, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", acc)

"""**Making a Predictive System**"""

# Making a Predictive System

# This should be a 2D array or list of lists, where each inner list is a sample
# The order of features should match the training data:
# Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age
new_data = np.array([
    [2, 150, 70, 30, 100, 30.5, 0.5, 35],
    [0, 100, 60, 20, 50, 25.0, 0.3, 25],
    [5, 180, 80, 35, 150, 35.0, 0.6, 45]
])

# Make predictions using the trained model
new_predictions_prob = model.predict(new_data)
new_predictions = (new_predictions_prob > 0.5).astype(int).flatten()

print("Predictions for new data (probabilities):", new_predictions_prob.flatten())
print("Predictions for new data (binary):", new_predictions)

# Add interpretation of predictions
print("\nInterpretation of predictions:")
for i, prediction in enumerate(new_predictions):
    status = "Diabetic" if prediction == 1 else "Non-Diabetic"
    print(f"Sample {i+1}: {status}")